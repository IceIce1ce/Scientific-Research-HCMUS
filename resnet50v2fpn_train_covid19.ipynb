{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet50v2fpn_train_covid19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Mca74lRWSKH"
      },
      "source": [
        "#For training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cw5GKT9Qm5xQ",
        "outputId": "fc74dc16-44d3-4e01-da68-880e1c0f5089"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gj650Gu2oSiN",
        "outputId": "b6aee269-8f39-4d88-cd24-ed7e7d6ea0dd"
      },
      "source": [
        "!pip install zipfile36\n",
        "!pip install git+https://github.com/mr7495/RetinaNet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting zipfile36\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/8a/3b7da0b0bd87d1ef05b74207827c72d348b56a0d6d83242582be18a81e02/zipfile36-0.1.3-py3-none-any.whl\n",
            "Installing collected packages: zipfile36\n",
            "Successfully installed zipfile36-0.1.3\n",
            "Collecting git+https://github.com/mr7495/RetinaNet\n",
            "  Cloning https://github.com/mr7495/RetinaNet to /tmp/pip-req-build-g2rtlbs7\n",
            "  Running command git clone -q https://github.com/mr7495/RetinaNet /tmp/pip-req-build-g2rtlbs7\n",
            "  Running command git submodule update --init --recursive -q\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (2.4.3)\n",
            "Collecting keras-resnet==0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/05/46/ad0b2d1a05d9497bd80c98a2c3f4d8be38a4601ace69af72814f5fafd851/keras-resnet-0.1.0.tar.gz\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (1.4.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (0.29.22)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (7.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (4.1.2.30)\n",
            "Requirement already satisfied: progressbar2 in /usr/local/lib/python3.7/dist-packages (from keras-retinanet==0.5.1) (3.38.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-retinanet==0.5.1) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-retinanet==0.5.1) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-retinanet==0.5.1) (3.13)\n",
            "Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from progressbar2->keras-retinanet==0.5.1) (2.5.6)\n",
            "Building wheels for collected packages: keras-retinanet, keras-resnet\n",
            "  Building wheel for keras-retinanet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-retinanet: filename=keras_retinanet-0.5.1-cp37-cp37m-linux_x86_64.whl size=181933 sha256=74823bd8bb159dc6d7e4db46697a6c4282ab6817cf7efb6843438f2fe7c9ada9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7jg7mkyq/wheels/08/6d/f5/38473102b36a5975e02e8f339fbf85bc4d1b1c7c80dc68a595\n",
            "  Building wheel for keras-resnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-resnet: filename=keras_resnet-0.1.0-py2.py3-none-any.whl size=13346 sha256=01604df6cf26854e47c0d8b5d931b88536151cd6416f79d2ea4d943a4a147b36\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/dd/ac/842235b63dddac12faa4b48ebe58b8944e8c2e57c2e38dddb6\n",
            "Successfully built keras-retinanet keras-resnet\n",
            "Installing collected packages: keras-resnet, keras-retinanet\n",
            "Successfully installed keras-resnet-0.1.0 keras-retinanet-0.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFG5RmDGpAUH"
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import csv\n",
        "import zipfile\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dropout, Flatten, Dense,Input\n",
        "from keras.applications.resnet_v2 import ResNet50V2\n",
        "from keras.applications.xception import Xception\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.initializers import RandomNormal\n",
        "import keras.backend as k\n",
        "from sklearn.utils import shuffle\n",
        "import io\n",
        "from PIL import Image as pil_image\n",
        "from keras_retinanet import layers\n",
        "import keras.backend as k\n",
        "import keras_retinanet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeyX7K0HpJjJ"
      },
      "source": [
        "archive = zipfile.ZipFile('/content/drive/MyDrive/Train&Validation.zip') \n",
        "for file in archive.namelist():\n",
        "     archive.extract(file, './data') #extract all image to folder data for training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edp6PvEWrAOM"
      },
      "source": [
        "#image data preprocessing\n",
        "fold_num = 2\n",
        "train_datagen = ImageDataGenerator(horizontal_flip = True, vertical_flip = True, zoom_range = 0.05, rotation_range = 360, width_shift_range = 0.05, height_shift_range = 0.05, shear_range = 0.05)\n",
        "test_datagen = ImageDataGenerator()\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/CSV/train{}.csv'.format(fold_num)) #read train csv file\n",
        "validation_df = pd.read_csv('/content/drive/MyDrive/CSV/validation{}.csv'.format(fold_num)) #read validation csv file (Validation in the training process)\n",
        "train_df = shuffle(train_df) #shuffle the train data\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/CSV/test{}.csv'.format(fold_num)) #read test csv file (For evaluating the final version of the trained network)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEE2nlrDtcqq"
      },
      "source": [
        "shape = (512, 512, 1) #shape of the dataset images (in TIFF format)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7RSpArfvcci",
        "outputId": "ff448917-8258-4fa1-b41f-4285c95c3933"
      },
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(dataframe = train_df, directory='data', x_col = \"filename\", y_col = \"class\", target_size = (512, 512), batch_size = 14,\n",
        "                                                    class_mode = 'categorical', color_mode = \"grayscale\", shuffle = True)\n",
        "validation_generator = test_datagen.flow_from_dataframe(dataframe = validation_df, directory = 'data', x_col = \"filename\", y_col = \"class\", target_size = (512, 512), batch_size = 10,\n",
        "                                                        class_mode = 'categorical', color_mode = \"grayscale\", shuffle=True)\n",
        "test_generator = test_datagen.flow_from_dataframe(dataframe = test_df, directory = 'data', x_col = \"filename\", y_col = \"class\", target_size = (512, 512), batch_size = 10,\n",
        "                                                  class_mode = 'categorical', color_mode = \"grayscale\", shuffle = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3715 validated image filenames belonging to 2 classes.\n",
            "Found 915 validated image filenames belonging to 2 classes.\n",
            "Found 8343 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UmBqWq8w_-E",
        "outputId": "2f28ccf7-5d1a-45ce-8df4-42e46b0a876c"
      },
      "source": [
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "\n",
        "k.clear_session() #clear keras backend \n",
        "try:\n",
        "  os.mkdir('models') #create folder for saving the model\n",
        "except:\n",
        "  pass\n",
        "full_name = 'ResNet50V2-FPN-fold{}'.format(fold_num)\n",
        "classes_number = 2 #normal and COVID-19\n",
        "input_tensor = Input(shape=shape)\n",
        "weight_model = ResNet50V2(weights='imagenet', include_top=False) #load ResNet50V2 ImageNet pre-trained weights\n",
        "weight_model.save_weights('weights.h5') #save the weights\n",
        "base_model = ResNet50V2(weights=None, include_top=False, input_tensor=input_tensor) #load the ResNet50V2 model without weights\n",
        "base_model.load_weights('weights.h5',skip_mismatch=True, by_name=True) #load the ImageNet weights on the ResNet50V2 model except the first layer(because the first layer has one channel in our case)\n",
        "#create FPN\n",
        "#https://github.com/fizyr/keras-retinanet/blob/master/keras_retinanet/models/retinanet.py\n",
        "feature_size = 256 #Set the feature channels of the FPN\n",
        "layer_names = [\"conv4_block1_preact_relu\", \"conv5_block1_preact_relu\", \"post_relu\"] #Layers of ResNet50V2 with different scale features \n",
        "layer_outputs = [base_model.get_layer(name).output for name in layer_names]\n",
        "C3, C4, C5 = layer_outputs #Features of different scales, extracted from ResNet50V2\n",
        "P5 = keras.layers.Conv2D(feature_size, kernel_size=1, strides=1, padding='same', name='C5_reduced')(C5)\n",
        "P5_upsampled = layers.UpsampleLike(name='P5_upsampled')([P5, C4])\n",
        "P5 = keras.layers.Conv2D(feature_size, kernel_size=3, strides=1, padding='same', name='P5')(P5)\n",
        "#Concatenate P5 elementwise to C4\n",
        "P4 = keras.layers.Conv2D(feature_size, kernel_size=1, strides=1, padding='same', name='C4_reduced')(C4)\n",
        "P4 = keras.layers.Concatenate(axis=3)([P5_upsampled, P4])\n",
        "P4_upsampled = layers.UpsampleLike(name='P4_upsampled')([P4, C3])\n",
        "P4 = keras.layers.Conv2D(feature_size, kernel_size=3, strides=1, name='P4')(P4)\n",
        "#Concatenate P4 elementwise to C3\n",
        "P3 = keras.layers.Conv2D(feature_size, kernel_size=1, strides=1, padding='same', name='C3_reduced')(C3)\n",
        "P3 = keras.layers.Concatenate(axis=3)([P4_upsampled, P3])\n",
        "P3 = keras.layers.Conv2D(feature_size, kernel_size=3, strides=1, name='P3')(P3)\n",
        "#P6 is obtained via a 3x3 stride-2 conv on C5\n",
        "P6 = keras.layers.Conv2D(feature_size, kernel_size=3, strides=2, padding='same', name='P6')(C5)\n",
        "#P7 is computed by applying ReLU followed by a 3x3 stride-2 conv on P6\n",
        "P7 = keras.layers.Activation('relu', name='C6_relu')(P6)\n",
        "P7 = keras.layers.Conv2D(feature_size, kernel_size=3, strides=2, padding='same', name='P7')(P7)\n",
        "#Run classification for each of the generated features from the pyramid\n",
        "feature1 = Flatten()(P3)\n",
        "dp1 = Dropout(0.5)(feature1)\n",
        "preds1 = Dense(2, activation='relu',kernel_initializer=RandomNormal(mean=0.0, stddev=0.001))(dp1)\n",
        "\n",
        "feature2 = Flatten()(P4)\n",
        "dp2 = Dropout(0.5)(feature2)\n",
        "preds2 = Dense(2, activation='relu',kernel_initializer=RandomNormal(mean=0.0, stddev=0.001))(dp2)\n",
        "\n",
        "feature3 = Flatten()(P5)\n",
        "dp3= Dropout(0.5)(feature3)\n",
        "preds3 = Dense(2, activation='relu',kernel_initializer=RandomNormal(mean=0.0, stddev=0.001))(dp3)\n",
        "\n",
        "feature4 = Flatten()(P6)\n",
        "dp4 = Dropout(0.5)(feature4)\n",
        "preds4 = Dense(2, activation='relu',kernel_initializer=RandomNormal(mean=0.0, stddev=0.001))(dp4)\n",
        "\n",
        "feature5 = Flatten()(P7)\n",
        "dp5 = Dropout(0.5)(feature5)\n",
        "preds5 = Dense(2, activation='relu',kernel_initializer=RandomNormal(mean=0.0, stddev=0.001))(dp5)\n",
        "\n",
        "concat = keras.layers.Concatenate(axis=1)([preds1, preds2, preds3, preds4, preds5]) #Concatenate the predictions(Classification results) of each of the pyramid features \n",
        "out = keras.layers.Dense(2, activation='softmax', kernel_initializer=RandomNormal(mean=0.0, stddev=0.001))(concat) #Final Classification\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=out) \n",
        "for layer in model.layers:\n",
        "  layer.trainable = True\n",
        "model.compile(optimizer=optimizers.Nadam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "filepath = \"models/%s-{epoch:02d}-{val_accuracy:.4f}.hdf5\"%full_name #path to save the model\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', save_best_only=True, mode='max') #save the best validation accuracy\n",
        "#model.fit_generator(train_generator, epochs=20, validation_data=validation_generator, shuffle=True, callbacks=[checkpoint]) \n",
        "early_stopper = EarlyStopping(monitor = 'val_loss', patience = 3)\n",
        "model.fit(train_generator, epochs=20, validation_data=validation_generator, shuffle=True, callbacks=[checkpoint, early_stopper]) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94674944/94668760 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:Skipping loading of weights for layer conv1_conv due to mismatch in shape ((7, 7, 1, 64) vs (64, 3, 7, 7)).\n",
            "Epoch 1/20\n",
            "266/266 [==============================] - 496s 2s/step - loss: 0.4274 - accuracy: 0.7902 - val_loss: 0.1847 - val_accuracy: 0.9399\n",
            "Epoch 2/20\n",
            "266/266 [==============================] - 430s 2s/step - loss: 0.1291 - accuracy: 0.9621 - val_loss: 0.2982 - val_accuracy: 0.9268\n",
            "Epoch 3/20\n",
            "266/266 [==============================] - 429s 2s/step - loss: 0.1132 - accuracy: 0.9599 - val_loss: 0.2970 - val_accuracy: 0.9060\n",
            "Epoch 4/20\n",
            "266/266 [==============================] - 429s 2s/step - loss: 0.0817 - accuracy: 0.9703 - val_loss: 0.1432 - val_accuracy: 0.9563\n",
            "Epoch 5/20\n",
            "266/266 [==============================] - 429s 2s/step - loss: 0.0780 - accuracy: 0.9771 - val_loss: 0.1059 - val_accuracy: 0.9716\n",
            "Epoch 6/20\n",
            "266/266 [==============================] - 429s 2s/step - loss: 0.0494 - accuracy: 0.9825 - val_loss: 0.2198 - val_accuracy: 0.9530\n",
            "Epoch 7/20\n",
            "266/266 [==============================] - 429s 2s/step - loss: 0.0715 - accuracy: 0.9749 - val_loss: 0.1996 - val_accuracy: 0.9355\n",
            "Epoch 8/20\n",
            "266/266 [==============================] - 428s 2s/step - loss: 0.0478 - accuracy: 0.9881 - val_loss: 0.1502 - val_accuracy: 0.9585\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd6f86f9c90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-19TuQnR65IO"
      },
      "source": [
        "!cp /content/models/ResNet50V2-FPN-fold2-05-0.9716.hdf5 /content/drive/MyDrive/backup_models/ResNet50V2_FPN_Fold2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oBHSD-u7ZEF"
      },
      "source": [
        "!rm -rf /content/models"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}